{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 7662018,
     "sourceType": "datasetVersion",
     "datasetId": 4467754
    }
   ],
   "dockerImageVersionId": 30648,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook for Training the Model (Video Anomaly Detection)\n",
    "---\n",
    "\n",
    "In this notebook we try to train our model with the embeddings that we got from previous notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installing Necessary Libraries\n",
    "\n",
    "Install Simple Recurrent Units in Kaggle. Make sure to install the `sru==3.0.0.dev6` version. This is to experiment with the SRUPP model. Also, you can install the current stable release `sru==2.6.0`\n",
    "\n",
    "**Make sure the Internet is ON**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install sru==3.0.0.dev6"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T14:53:20.630802Z",
     "iopub.execute_input": "2024-02-21T14:53:20.631431Z",
     "iopub.status.idle": "2024-02-21T14:53:33.734022Z",
     "shell.execute_reply.started": "2024-02-21T14:53:20.631400Z",
     "shell.execute_reply": "2024-02-21T14:53:33.732955Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting sru==3.0.0.dev6\n  Downloading sru-3.0.0.dev6-py3-none-any.whl (30 kB)\nRequirement already satisfied: torch>=1.5.1 in /opt/conda/lib/python3.10/site-packages (from sru==3.0.0.dev6) (2.1.2)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from sru==3.0.0.dev6) (1.11.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.1->sru==3.0.0.dev6) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.1->sru==3.0.0.dev6) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.1->sru==3.0.0.dev6) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.1->sru==3.0.0.dev6) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.1->sru==3.0.0.dev6) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.1->sru==3.0.0.dev6) (2023.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.5.1->sru==3.0.0.dev6) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.5.1->sru==3.0.0.dev6) (1.3.0)\nInstalling collected packages: sru\nSuccessfully installed sru-3.0.0.dev6\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing necessary Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section we import the libraries that we need. We are using torch framework to train our model. We are also using Simple Recurrent Unit (SRU). We also import some utility functions to view real time progression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sru import SRU\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import Module, Dropout, Linear\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T14:53:36.477578Z",
     "iopub.execute_input": "2024-02-21T14:53:36.477947Z",
     "iopub.status.idle": "2024-02-21T14:54:28.335907Z",
     "shell.execute_reply.started": "2024-02-21T14:53:36.477904Z",
     "shell.execute_reply": "2024-02-21T14:54:28.335080Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Selecting Computing Device\n",
    "\n",
    "Automatically selects the best hardware accelerator that is available on the system"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Set the device to use (e.g., 'cpu', 'cuda', 'mps')\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else\n",
    "                      (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Select Device According to Availability\n",
    "print(\"Device selected:\", device)\n",
    "\n",
    "# If the device is CUDA, print the device capability\n",
    "if device.type == \"cuda\":\n",
    "    os.system(\"nvidia-smi\")\n",
    "    print()\n",
    "    print(\"Device type:\", device.type)\n",
    "    print(\"Capability:\", torch.cuda.get_device_capability(device))\n",
    "else:\n",
    "    print(\"Device capabilities are limited on MPSs and CPUs.\")"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-02-21T14:54:33.651173Z",
     "iopub.execute_input": "2024-02-21T14:54:33.651692Z",
     "iopub.status.idle": "2024-02-21T14:54:33.704054Z",
     "shell.execute_reply.started": "2024-02-21T14:54:33.651662Z",
     "shell.execute_reply": "2024-02-21T14:54:33.703113Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "Device selected: cuda\nWed Feb 21 14:54:33 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   30C    P0              26W / 250W |      2MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n\nDevice type: cuda\nCapability: (6, 0)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the Dataset\n",
    "\n",
    "Here we prepare our training and testing dataset. We do the following things:\n",
    "\n",
    "- Load the files from Kaggle Input and check if the file has correct shapes and sizes\n",
    "- Split the dataset in Training and Testing\n",
    "- Create Dataloader for model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading and Checking the saved npy files\n",
    "\n",
    "Our files can be found in \n",
    "\n",
    "- video_embeddings - `/kaggle/input/embeddings-v1/embeddings.npy`\n",
    "- labels - `/kaggle/input/embeddings-v1/labels.npy`\n",
    "\n",
    "Load them with `np.load()` function and check if they match the lengths and shapes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "file_embeddings = np.load('/kaggle/input/embeddings-v1/embeddings.npy')\n",
    "file_labels = np.load('/kaggle/input/embeddings-v1/labels.npy')\n",
    "\n",
    "# Check if the embeddings and labels are of the same length\n",
    "if len(file_embeddings) != len(file_labels):\n",
    "    raise ValueError(\"The length of the embeddings and labels should be the same\")\n",
    "\n",
    "# check if the embedding is a 4D array\n",
    "if len(file_embeddings.shape) != 4:\n",
    "    raise ValueError(f\"The embeddings should be a 4D array [instances, windows, frames, features].\"\n",
    "                     f\" Found {len(file_embeddings.shape)}D instead.\")\n",
    "\n",
    "print(\"Files Loaded Successfully\")\n",
    "print(\"Video Embeddings Shape:\", file_embeddings.shape)\n",
    "print(\"Video Labels Shape:\", file_labels.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T15:27:42.806735Z",
     "iopub.execute_input": "2024-02-21T15:27:42.807449Z",
     "iopub.status.idle": "2024-02-21T15:27:43.281782Z",
     "shell.execute_reply.started": "2024-02-21T15:27:42.807414Z",
     "shell.execute_reply": "2024-02-21T15:27:43.280807Z"
    },
    "trusted": true
   },
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "text": "Files Loaded Successfully\nVideo Embeddings Shape: (3636, 4, 24, 1024)\nVideo Labels Shape: (3636,)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train-Test Splitting\n",
    "\n",
    "We use typical `train_test_split()` function from scikit-learn library to split the dataset into `x_train`, `y_train`, `x_test`, `y_test`.\n",
    "\n",
    "**But before that,**\n",
    "\n",
    "We change the shape of video embeddings to 2D array. Initially it was 4D array but due to SRU model input compatibility, we changed the shape to 2D. Previously, the shape was `[videos, window, frames, features]` but we changed them to `[videos*window, frames*features]`. Which means, we take the total windows and all the features from our dataset.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "test_size = 0.2\n",
    "\n",
    "# Change the shape to fit the model (into 2d Array)\n",
    "embeddings = file_embeddings.reshape(file_embeddings.shape[0] * file_embeddings.shape[1], -1)\n",
    "labels = np.repeat(file_labels, 4)\n",
    "\n",
    "# Split the data into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(embeddings,\n",
    "                                                    labels,\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# convert to tensor\n",
    "train_embeddings = torch.from_numpy(x_train).to(device)\n",
    "train_labels = torch.from_numpy(y_train).to(device)\n",
    "test_embeddings = torch.from_numpy(x_test).to(device)\n",
    "test_labels = torch.from_numpy(y_test).to(device)\n",
    "\n",
    "print('Shape of Train Embeddings:', train_embeddings.shape)\n",
    "print('Shape of Train Labels:', train_labels.shape)\n",
    "print('Shape of Test Embeddings:', test_embeddings.shape)\n",
    "print('Shape of Test Labels:', test_labels.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T15:24:24.360931Z",
     "iopub.execute_input": "2024-02-21T15:24:24.361619Z",
     "iopub.status.idle": "2024-02-21T15:24:25.079142Z",
     "shell.execute_reply.started": "2024-02-21T15:24:24.361586Z",
     "shell.execute_reply": "2024-02-21T15:24:25.078059Z"
    },
    "trusted": true
   },
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "text": "Shape of Train Embeddings: torch.Size([11635, 24576])\nShape of Train Labels: torch.Size([11635])\nShape of Test Embeddings: torch.Size([2909, 24576])\nShape of Test Labels: torch.Size([2909])\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating TensorDataset and Dataloader\n",
    "\n",
    "To feed data into our model for training, we made a Dataloader. First we converted them into `TensorDataset` object, then with them, we instantiated `DataLoader` objects"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 8\n",
    "\n",
    "# Create TensorDataset\n",
    "train_data = TensorDataset(train_embeddings, train_labels)\n",
    "test_data = TensorDataset(test_embeddings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T15:01:09.091781Z",
     "iopub.execute_input": "2024-02-21T15:01:09.092381Z",
     "iopub.status.idle": "2024-02-21T15:01:09.097588Z",
     "shell.execute_reply.started": "2024-02-21T15:01:09.092347Z",
     "shell.execute_reply": "2024-02-21T15:01:09.096661Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the Model\n",
    "\n",
    "We build our model with SRU, Dropout Layer and Fully Connected Layer. Model Structure is given below:\n",
    "\n",
    "    SRUModel(\n",
    "      (sru_layers): SRU(\n",
    "        (rnn_lst): ModuleList(\n",
    "          (0): SRUCell(24576, 1024, rescale=True,\n",
    "            transform_module=Linear(in_features=24576, out_features=4096, bias=False)\n",
    "          )\n",
    "          (1): SRUCell(1024, 1024, rescale=True,\n",
    "            transform_module=Linear(in_features=1024, out_features=3072, bias=False)\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "      (dropout): Dropout(p=0.2, inplace=False)\n",
    "      (linear): Linear(in_features=1024, out_features=2, bias=True)\n",
    "    )"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Structure and Initialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class SRUModel(Module):\n",
    "    def __init__(self, input_size, hidden_size, **kwargs):\n",
    "        super(SRUModel, self).__init__()\n",
    "        # Main SRU layer\n",
    "        self.sru_layers = SRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=kwargs.get('num_layers', 2),\n",
    "            dropout=kwargs.get('dropout_prob', 0.0),\n",
    "            bidirectional=kwargs.get('bidirectional', False),\n",
    "            layer_norm=kwargs.get('layer_norm', False),\n",
    "            highway_bias=kwargs.get('highway_bias', 0.0),\n",
    "            rescale=kwargs.get('rescale', True),\n",
    "            nn_rnn_compatible_return=kwargs.get('nn_rnn_compatible_return', False),\n",
    "            proj_input_to_hidden_first=kwargs.get('proj_input_to_hidden_first', False),\n",
    "            amp_recurrence_fp16=kwargs.get('amp_recurrence_fp16', False),\n",
    "            normalize_after=kwargs.get('normalize_after', False),\n",
    "        ).to(device)\n",
    "        # Dropout layer\n",
    "        self.dropout = Dropout(kwargs.get('dropout_layer_prob', 0.2)).to(device)\n",
    "        # Linear layer (Fully connected layer)\n",
    "        self.linear = Linear(\n",
    "            in_features=hidden_size * 2 if kwargs.get('bidirectional', False) else hidden_size,\n",
    "            out_features=kwargs.get('num_classes', 2)\n",
    "        ).to(device)\n",
    "        # L2 regularization\n",
    "        self.l2_reg_lambda = kwargs.get('l2_reg_lambda', 1e-5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_states, _ = self.sru_layers(x)\n",
    "        output = self.linear(self.dropout(output_states[-1]))\n",
    "        return output\n",
    "\n",
    "    def l2_regularization(self):\n",
    "        l2_reg = torch.tensor(0., device=device)\n",
    "        for param in self.parameters():\n",
    "            l2_reg += torch.norm(param, p=2)\n",
    "        return self.l2_reg_lambda * l2_reg\n",
    "\n",
    "\n",
    "model = SRUModel(24576, 1024)\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T15:29:55.955561Z",
     "iopub.execute_input": "2024-02-21T15:29:55.956278Z",
     "iopub.status.idle": "2024-02-21T15:29:57.884931Z",
     "shell.execute_reply.started": "2024-02-21T15:29:55.956247Z",
     "shell.execute_reply": "2024-02-21T15:29:57.884112Z"
    },
    "trusted": true
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Loss function and Optimizer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Define your loss function and optimizer\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T15:08:48.193916Z",
     "iopub.execute_input": "2024-02-21T15:08:48.194227Z",
     "iopub.status.idle": "2024-02-21T15:08:48.199236Z",
     "shell.execute_reply.started": "2024-02-21T15:08:48.194202Z",
     "shell.execute_reply": "2024-02-21T15:08:48.198319Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(filename='training.log', level=logging.INFO)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Create tqdm progress bar for training loader\n",
    "    progress_bar = tqdm(enumerate(train_loader), desc=f\"Epoch {epoch + 1}/{epochs}\", total=len(train_loader))\n",
    "\n",
    "    for i, (videos, labels) in progress_bar:\n",
    "        videos = videos.unsqueeze(0)\n",
    "        # Forward pass\n",
    "        outputs = model(videos)\n",
    "        labels = labels.long()  # Convert labels to Long type\n",
    "        loss = criterion(outputs, labels) + model.l2_regularization()  # calculates loss\n",
    "        total_loss += loss.item()\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Calculate accuracy per batch\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        batch_accuracy = 100 * total_correct / total_samples\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix(loss=loss.item(), accuracy=batch_accuracy)\n",
    "\n",
    "    # Log epoch statistics\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * total_correct / total_samples\n",
    "    logging.info(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss}, Accuracy: {epoch_accuracy}%')\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss}, Accuracy: {epoch_accuracy}%')\n",
    "\n",
    "# Close logging\n",
    "logging.shutdown()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T15:10:20.411368Z",
     "iopub.execute_input": "2024-02-21T15:10:20.412380Z",
     "iopub.status.idle": "2024-02-21T15:16:50.772341Z",
     "shell.execute_reply.started": "2024-02-21T15:10:20.412337Z",
     "shell.execute_reply": "2024-02-21T15:16:50.771440Z"
    },
    "trusted": true
   },
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "text": "Epoch 1/10: 100%|██████████| 1455/1455 [00:39<00:00, 37.29it/s, accuracy=96.5, loss=0.00713]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch [1/10], Loss: 0.10224267991349306, Accuracy: 96.46755479157714%\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 2/10: 100%|██████████| 1455/1455 [00:39<00:00, 37.28it/s, accuracy=99.1, loss=0.00686]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch [2/10], Loss: 0.037275684418163146, Accuracy: 99.07176622260421%\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 3/10: 100%|██████████| 1455/1455 [00:39<00:00, 37.27it/s, accuracy=99.3, loss=0.00701]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch [3/10], Loss: 0.03468061937019229, Accuracy: 99.26944563816072%\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 4/10: 100%|██████████| 1455/1455 [00:38<00:00, 37.32it/s, accuracy=99.4, loss=0.00786]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch [4/10], Loss: 0.025703284755682003, Accuracy: 99.41555651052857%\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 5/10: 100%|██████████| 1455/1455 [00:39<00:00, 37.26it/s, accuracy=99.5, loss=0.00885]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch [5/10], Loss: 0.02340372176776893, Accuracy: 99.47571981091534%\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 6/10: 100%|██████████| 1455/1455 [00:39<00:00, 37.26it/s, accuracy=99.3, loss=0.0238] \n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch [6/10], Loss: 0.030376053315705757, Accuracy: 99.33820369574559%\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 7/10: 100%|██████████| 1455/1455 [00:39<00:00, 37.28it/s, accuracy=99.4, loss=0.00769]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch [7/10], Loss: 0.030124324103465296, Accuracy: 99.41555651052857%\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 8/10: 100%|██████████| 1455/1455 [00:39<00:00, 37.30it/s, accuracy=99.8, loss=0.00766]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch [8/10], Loss: 0.013608307863787278, Accuracy: 99.76794155565105%\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 9/10: 100%|██████████| 1455/1455 [00:39<00:00, 37.27it/s, accuracy=99.3, loss=0.00777]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch [9/10], Loss: 0.03598142198776615, Accuracy: 99.30382466695316%\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Epoch 10/10: 100%|██████████| 1455/1455 [00:39<00:00, 37.24it/s, accuracy=99.6, loss=0.00783]\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch [10/10], Loss: 0.022069227149153187, Accuracy: 99.57885689729265%\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for videos, labels in tqdm(test_loader, desc=\"Evaluating the Model\"):\n",
    "        videos = videos.unsqueeze(0)\n",
    "        outputs = model(videos)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy of the model on the test dataset: {test_accuracy}%')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T15:16:58.218658Z",
     "iopub.execute_input": "2024-02-21T15:16:58.219278Z",
     "iopub.status.idle": "2024-02-21T15:16:58.827407Z",
     "shell.execute_reply.started": "2024-02-21T15:16:58.219242Z",
     "shell.execute_reply": "2024-02-21T15:16:58.826548Z"
    },
    "trusted": true
   },
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "text": "Evaluating the Model: 100%|██████████| 364/364 [00:00<00:00, 608.82it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Test Accuracy of the model on the test dataset: 99.55311103471983%\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model.state_dict(), 'anomaly_detection_model.pt')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-21T15:17:54.409755Z",
     "iopub.execute_input": "2024-02-21T15:17:54.410489Z",
     "iopub.status.idle": "2024-02-21T15:17:55.192938Z",
     "shell.execute_reply.started": "2024-02-21T15:17:54.410455Z",
     "shell.execute_reply": "2024-02-21T15:17:55.192124Z"
    },
    "trusted": true
   },
   "execution_count": 43,
   "outputs": []
  }
 ]
}
